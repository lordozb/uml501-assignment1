{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment 1\n",
    "<br>\n",
    "## Name: Abhishek Salwan                                                                                                          \n",
    "## Course: COE\n",
    "## Roll No: 101503007                                                                                                                   \n",
    "## Batch: COE1\n",
    "<br>\n",
    "\n",
    "# PART I \n",
    "# [For Regression Dataset | filename: regressionDataSet.csv]\n",
    "<br>\n",
    "\n",
    "## Q1.1\tCompare the performance of 10 machine learning models for given regression data set for thedata partition of 70-30% with acceptable error of Â±100.\n",
    "\n",
    "### Table 1.1: Comparative Performance Study of Machine Learning Models\n",
    "\n",
    "<table class=\"table table-bordered\">\n",
    "\n",
    "<tr>\n",
    "<th >Model</th>\n",
    "<th style=\"width:\">Method</th>\n",
    "<th style=\"width:\">Package</th>\n",
    "<th style=\"width:\">r</th>\n",
    "<th style=\"width:\">R<sup>2</sup></th>\n",
    "<th style=\"width:\">Error</th>\n",
    "<th style=\"width:\">Accuracy</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>M1</td>\n",
    "<td>Linear</td>\n",
    "<td>sklearn.linear_model</td>\n",
    "<td>1.0</td>\n",
    "<td>1.0</td>\n",
    "<td>0.0000001</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M2</td>\n",
    "<td>Polynomial</td>\n",
    "<td>sklearn.linear_model</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.0009</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M3</td>\n",
    "<td>Lasso</td>\n",
    "<td>sklearn.linear_model</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.9998</td>\n",
    "<td>11.175</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>M4</td>\n",
    "<td>Elastic Net</td>\n",
    "<td>sklearn.linear_model</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.9999</td>\n",
    "<td>3.7032</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M5</td>\n",
    "<td>Ridge</td>\n",
    "<td>sklearn.linear_model</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.000004</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M6</td>\n",
    "<td>Bayesian Ridge</td>\n",
    "<td>sklearn.linear_model</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.0474</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M7</td>\n",
    "<td>Kernel Ridge</td>\n",
    "<td>sklearn.kernel_ridge</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.000004</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M8</td>\n",
    "<td>K-Neighbors</td>\n",
    "<td>sklearn.neighbors</td>\n",
    "<td>0.9988</td>\n",
    "<td>0.9976</td>\n",
    "<td>41.8680</td>\n",
    "<td>94.4281</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M9</td>\n",
    "<td>Decision Tree</td>\n",
    "<td>sklearn.tree</td>\n",
    "<td>0.9981</td>\n",
    "<td>0.9962</td>\n",
    "<td>50.611</td>\n",
    "<td>86.133</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M10</td>\n",
    "<td>Random Forest</td>\n",
    "<td>sklearn.ensemble</td>\n",
    "<td>0.9990</td>\n",
    "<td>0.9980</td>\n",
    "<td>40.0374</td>\n",
    "<td>98.0310</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1 - Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#fitting the model on the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2 - Polynomimal Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#fitting the model on the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg=PolynomialFeatures(degree=4)\n",
    "x_poly=poly_reg.fit_transform(x_train)\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(x_poly,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred=regressor.predict(poly_reg.fit_transform(x_test))\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M3 - Lasso Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#fitting the model on the training set\n",
    "from sklearn.linear_model import Lasso\n",
    "regressor=Lasso(max_iter=10000)    \n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M4 - Elastic Net Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#fitting the model on the training set\n",
    "from sklearn.linear_model import ElasticNet\n",
    "regressor=ElasticNet(max_iter=10000)\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M5 - Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#fitting the model on the training set\n",
    "from sklearn.linear_model import Ridge\n",
    "regressor=Ridge()\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M6 - Bayesian Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#fitting the model on the training set\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "regressor=BayesianRidge()\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M7 - Kernel Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#fitting the model on the training set\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "regressor=KernelRidge()\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M8 - K-Neighbors Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#fitting the model on the training set\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "regressor=KNeighborsRegressor(n_neighbors=3)\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9 - Decision Tree Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#fitting the model on the training set\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor=DecisionTreeRegressor(criterion='mae')\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M10 - Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#fitting the model on the training set\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor=RandomForestRegressor(n_estimators=500,random_state=0)\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2\tEnsemble the models from Table 1.1 for data partition for given regression data set of 70-30%and with acceptable error of Â±100.\n",
    "\n",
    "### Table 1.2: Result analysis of ensemble models\n",
    "\n",
    "\n",
    "<table class=\"table table-bordered\">\n",
    "\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th>Combination</th>\n",
    "<th>r</th>\n",
    "<th>R<sup>2</sup></th>\n",
    "<th>Error</th>\n",
    "<th>Accuracy</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>E1</td>\n",
    "<td>M1,M5,M6,M7,M10</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.9999</td>\n",
    "<td>7.8300</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>E2</td>\n",
    "<td>M1,M2,M4,M9,M10</td>\n",
    "<td>0.9998</td>\n",
    "<td>0.9996</td>\n",
    "<td>16.7008</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>E3</td>\n",
    "<td>M2,M4,M6,M8,M10</td>\n",
    "<td>0.9998</td>\n",
    "<td>0.9996</td>\n",
    "<td>15.9994</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>E4</td>\n",
    "<td>M1,M3,M5,M7</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.9999</td>\n",
    "<td>0.000003</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>E5</td>\n",
    "<td>M1,M2,M6,M8,M10</td>\n",
    "<td>0.9998</td>\n",
    "<td>0.9996</td>\n",
    "<td>16.4602</td>\n",
    "<td>100.0</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1 - M1,M5,M6,M7,M10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "#fitting the linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor1=LinearRegression()\n",
    "regressor1.fit(x_train,y_train)\n",
    "y_pred1=regressor1.predict(x_test)\n",
    "df['pred1']=y_pred1\n",
    "\n",
    "#fitting the ridge model\n",
    "from sklearn.linear_model import Ridge\n",
    "regressor2=Ridge()\n",
    "regressor2.fit(x_train,y_train)\n",
    "y_pred2=regressor2.predict(x_test)\n",
    "df['pred2']=y_pred2\n",
    "\n",
    "#fitting the bayesian ridge model\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "regressor3=BayesianRidge()\n",
    "regressor3.fit(x_train,y_train)\n",
    "y_pred3=regressor3.predict(x_test)\n",
    "df['pred3']=y_pred3\n",
    "\n",
    "#fitting the kernel ridge model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "regressor4=KernelRidge()\n",
    "regressor4.fit(x_train,y_train)\n",
    "y_pred4=regressor4.predict(x_test)\n",
    "df['pred4']=y_pred4\n",
    "\n",
    "#fitting the random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor5=RandomForestRegressor(n_estimators=500,random_state=0)\n",
    "regressor5.fit(x_train,y_train)\n",
    "y_pred5=regressor5.predict(x_test)\n",
    "df['pred5']=y_pred5\n",
    "\n",
    "#ensembling\n",
    "y_pred=df.mean(axis=1)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E2 - M1,M2,M4,M9,M10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "#fitting the linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor1=LinearRegression()\n",
    "regressor1.fit(x_train,y_train)\n",
    "y_pred1=regressor1.predict(x_test)\n",
    "df['pred1']=y_pred1\n",
    "\n",
    "#fitting the polynomial model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg=PolynomialFeatures(degree=4)\n",
    "x_poly=poly_reg.fit_transform(x_train)\n",
    "regressor2=LinearRegression()\n",
    "regressor2.fit(x_poly,y_train)\n",
    "y_pred2=regressor2.predict(poly_reg.fit_transform(x_test))\n",
    "df['pred2']=y_pred2\n",
    "\n",
    "#fitting the elastic net model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "regressor3=ElasticNet(max_iter=10000)\n",
    "regressor3.fit(x_train,y_train)\n",
    "y_pred3=regressor3.predict(x_test)\n",
    "df['pred3']=y_pred3\n",
    "\n",
    "#fitting the decision tree model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor4=DecisionTreeRegressor(criterion='mae')\n",
    "regressor4.fit(x_train,y_train)\n",
    "y_pred4=regressor4.predict(x_test)\n",
    "df['pred4']=y_pred4\n",
    "\n",
    "#fitting the random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor5=RandomForestRegressor(n_estimators=500,random_state=0)\n",
    "regressor5.fit(x_train,y_train)\n",
    "y_pred5=regressor5.predict(x_test)\n",
    "df['pred5']=y_pred5\n",
    "\n",
    "#ensembling\n",
    "y_pred=df.mean(axis=1)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E3 - M2,M4,M6,M8,M10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "#fitting the polynomial model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg=PolynomialFeatures(degree=4)\n",
    "x_poly=poly_reg.fit_transform(x_train)\n",
    "regressor1=LinearRegression()\n",
    "regressor1.fit(x_poly,y_train)\n",
    "y_pred1=regressor1.predict(poly_reg.fit_transform(x_test))\n",
    "df['pred1']=y_pred1\n",
    "\n",
    "#fitting the elastic net model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "regressor2=ElasticNet(max_iter=10000)\n",
    "regressor2.fit(x_train,y_train)\n",
    "y_pred2=regressor2.predict(x_test)\n",
    "df['pred2']=y_pred2\n",
    "\n",
    "#fitting the bayesian ridge model\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "regressor3=BayesianRidge()\n",
    "regressor3.fit(x_train,y_train)\n",
    "y_pred3=regressor3.predict(x_test)\n",
    "df['pred3']=y_pred3\n",
    "\n",
    "#fitting the k neighbors model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "regressor4=KNeighborsRegressor(n_neighbors=3)\n",
    "regressor4.fit(x_train,y_train)\n",
    "y_pred4=regressor4.predict(x_test)\n",
    "df['pred4']=y_pred4\n",
    "\n",
    "#fitting the random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor5=RandomForestRegressor(n_estimators=500,random_state=0)\n",
    "regressor5.fit(x_train,y_train)\n",
    "y_pred5=regressor5.predict(x_test)\n",
    "df['pred5']=y_pred5\n",
    "\n",
    "#ensembling\n",
    "y_pred=df.mean(axis=1)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E4 - M1,M3,M5,M7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "#fitting the linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor1=LinearRegression()\n",
    "regressor1.fit(x_train,y_train)\n",
    "y_pred1=regressor1.predict(x_test)\n",
    "df['pred1']=y_pred1\n",
    "\n",
    "#fitting the lasso model\n",
    "from sklearn.linear_model import Lasso\n",
    "regressor2=Lasso(max_iter=10000)    \n",
    "regressor2.fit(x_train,y_train)\n",
    "y_pred2=regressor2.predict(x_test)\n",
    "df['pred2']=y_pred2\n",
    "\n",
    "#fitting the ridge model\n",
    "from sklearn.linear_model import Ridge\n",
    "regressor3=Ridge()\n",
    "regressor3.fit(x_train,y_train)\n",
    "y_pred3=regressor3.predict(x_test)\n",
    "df['pred2']=y_pred3\n",
    "\n",
    "#fitting the kernel ridge model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "regressor4=KernelRidge()\n",
    "regressor4.fit(x_train,y_train)\n",
    "y_pred4=regressor4.predict(x_test)\n",
    "df['pred4']=y_pred4\n",
    "\n",
    "#ensembling\n",
    "y_pred=df.mean(axis=1)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E5 - M1,M2,M6,M8,M10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "#fitting the linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor1=LinearRegression()\n",
    "regressor1.fit(x_train,y_train)\n",
    "y_pred1=regressor1.predict(x_test)\n",
    "df['pred1']=y_pred1\n",
    "\n",
    "#fitting the polynomial model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg=PolynomialFeatures(degree=4)\n",
    "x_poly=poly_reg.fit_transform(x_train)\n",
    "regressor2=LinearRegression()\n",
    "regressor2.fit(x_poly,y_train)\n",
    "y_pred2=regressor2.predict(poly_reg.fit_transform(x_test))\n",
    "df['pred2']=y_pred2\n",
    "\n",
    "#fitting the bayesian ridge model\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "regressor3=BayesianRidge()\n",
    "regressor3.fit(x_train,y_train)\n",
    "y_pred3=regressor3.predict(x_test)\n",
    "df['pred3']=y_pred3\n",
    "\n",
    "#fitting the k neighbors model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "regressor4=KNeighborsRegressor(n_neighbors=3)\n",
    "regressor4.fit(x_train,y_train)\n",
    "y_pred4=regressor4.predict(x_test)\n",
    "df['pred4']=y_pred4\n",
    "\n",
    "#fitting the random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor5=RandomForestRegressor(n_estimators=500,random_state=0)\n",
    "regressor5.fit(x_train,y_train)\n",
    "y_pred5=regressor5.predict(x_test)\n",
    "df['pred5']=y_pred5\n",
    "\n",
    "#ensembling\n",
    "y_pred=df.mean(axis=1)\n",
    "\n",
    "#calculating r2\n",
    "r2=r2_score(y_test,y_pred)\n",
    "\n",
    "#calculating r\n",
    "r=m.sqrt(r2)\n",
    "\n",
    "#calculating error\n",
    "error=mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "#calculating accuracy\n",
    "accuracy = (float)(np.count_nonzero(np.array(abs(y_test - y_pred) <= 100))/np.size(y_test))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3\tStudy 5 feature selection techniques for given regression data set and report Top five features.\n",
    "\n",
    "### Table 1.3: Study of feature selection techniques\n",
    "\n",
    "\n",
    "<table class=\"table table-bordered\">\n",
    "\n",
    "<tr>\n",
    "<th>Feature Selection Technique</th>\n",
    "<th>Top 5 Features</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>T1 - SelectKBest</td>\n",
    "<td>F5,F6,F8,F9,F10</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>T2 - SelectFdr</td>\n",
    "<td>F1,F2,F4,F5,F6</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>T3 - RFE</td>\n",
    "<td>F1,F2,F3,F4,F14</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>T4 - SelectFromModel</td>\n",
    "<td>F1,F2,F3,F4,F14</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>T5 - SelectFwe</td>\n",
    "<td>F1,F2,F3,F4,F5</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('regressionDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#feature selector 1\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "fs1=SelectKBest(k=5)\n",
    "x_new1=fs1.fit_transform(x,y)\n",
    "\n",
    "#feature selector 2\n",
    "from sklearn.feature_selection import SelectFdr\n",
    "fs2=SelectFdr()\n",
    "x_new2=fs2.fit_transform(x,y)\n",
    "\n",
    "#feature selector 3\n",
    "from sklearn.linear_model import LinearRegression\n",
    "estimator = LinearRegression()\n",
    "from sklearn.feature_selection import RFE\n",
    "fs3=RFE(estimator,5)\n",
    "x_new3=fs3.fit_transform(x,y)\n",
    "\n",
    "#feature selector 4\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "fs4=SelectFromModel(estimator)\n",
    "x_new4=fs4.fit_transform(x,y)\n",
    "\n",
    "#feature selector 5\n",
    "from sklearn.feature_selection import SelectFwe\n",
    "fs5=SelectFwe()\n",
    "x_new5=fs5.fit_transform(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "# PART II\n",
    "# [For Classification Dataset | filename: classificationDataSet.csv]\n",
    "<br>\n",
    "\n",
    "## Q2.1 \tCompare the performance of 10 machine learning models for given classification data set for the data partition of 70-30%.\n",
    "\n",
    "### Table 2.1: Comparative Performance Study of Machine Learning Models\n",
    "\n",
    "<table class=\"table table-bordered\">\n",
    "\n",
    "<tr>\n",
    "<th style=\"width:\">Model</th>\n",
    "<th style=\"width:\">Method</th>\n",
    "<th style=\"width:\">Package</th>\n",
    "<th style=\"width:\">Sensitivity</th>\n",
    "<th style=\"width:\">Specificity</th>\n",
    "<th style=\"width:\">Precision</th>\n",
    "<th style=\"width:\">Recall</th>\n",
    "<th style=\"width:\">Accuracy</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>M1</td>\n",
    "<td>Logistic Regression</td>\n",
    "<td>sklearn.linear_model</td>\n",
    "<td>0.6744</td>\n",
    "<td>0.3770</td>\n",
    "<td>0.5357</td>\n",
    "<td>0.6744</td>\n",
    "<td>0.5304</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M2</td>\n",
    "<td>SGD</td>\n",
    "<td>sklearn.linear_model</td>\n",
    "<td>0.4262</td>\n",
    "<td>0.5175</td>\n",
    "<td>0.4840</td>\n",
    "<td>0.4262</td>\n",
    "<td>0.4704</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M3</td>\n",
    "<td>Naive Bayes</td>\n",
    "<td>sklearn.naive_bayes</td>\n",
    "<td>0.5560</td>\n",
    "<td>0.4565</td>\n",
    "<td>0.5227</td>\n",
    "<td>0.5560</td>\n",
    "<td>0.5080</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>M4</td>\n",
    "<td>SVC</td>\n",
    "<td>sklearn.svm</td>\n",
    "<td>0.6298</td>\n",
    "<td>0.4070</td>\n",
    "<td>0.5444</td>\n",
    "<td>0.6298</td>\n",
    "<td>0.5250</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M5</td>\n",
    "<td>Gaussian Process</td>\n",
    "<td>sklearn.gaussian_process</td>\n",
    "<td>0.5942</td>\n",
    "<td>0.4265</td>\n",
    "<td>0.5154</td>\n",
    "<td>0.5942</td>\n",
    "<td>0.5114</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M6</td>\n",
    "<td>K-Nieghbors</td>\n",
    "<td>sklearn.neighbors</td>\n",
    "<td>0.5833</td>\n",
    "<td>0.4299</td>\n",
    "<td>0.5277</td>\n",
    "<td>0.5833</td>\n",
    "<td>0.5100</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M7</td>\n",
    "<td>Nearest Centroid</td>\n",
    "<td>sklearn.neighbors</td>\n",
    "<td>0.5670</td>\n",
    "<td>0.5015</td>\n",
    "<td>0.5426</td>\n",
    "<td>0.5670</td>\n",
    "<td>0.5350</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M8</td>\n",
    "<td>Radius Nieghbors</td>\n",
    "<td>sklearn.neighbors</td>\n",
    "<td>1.0</td>\n",
    "<td>0.0</td>\n",
    "<td>0.502</td>\n",
    "<td>1.0</td>\n",
    "<td>0.502</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M9</td>\n",
    "<td>Decision Tree</td>\n",
    "<td>sklearn.tree</td>\n",
    "<td>0.5194</td>\n",
    "<td>0.4984</td>\n",
    "<td>0.5352</td>\n",
    "<td>0.5194</td>\n",
    "<td>0.5094</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>M10</td>\n",
    "<td>Random Forest</td>\n",
    "<td>sklearn.ensemble</td>\n",
    "<td>0.5958</td>\n",
    "<td>0.41658</td>\n",
    "<td>0.49279</td>\n",
    "<td>0.59589</td>\n",
    "<td>0.504</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1 - Logisctic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(max_iter=10000)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2 - SGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M3 - Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M4 - SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.svm import SVC\n",
    "classifier=SVC(max_iter=10000,kernel='rbf')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M5 - Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "classifier = GaussianProcessClassifier()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M6 - K-Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier(n_neighbors=100)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M7 - Nearest Centroid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "classifier = NearestCentroid()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M8 - Radius Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "classifier= RadiusNeighborsClassifier(radius=10)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9 - Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='entropy')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M10 - Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(n_estimators=500,criterion='entropy')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.2\tEnsemble the models from Table 2.1 for given classification data set on data partition of 70-30%.\n",
    "\n",
    "### Table 2.2: Result analysis of ensemble models\n",
    "\n",
    "<table class=\"table table-bordered\">\n",
    "\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th>Combination</th>\n",
    "<th>Sensitivity</th>\n",
    "<th>Specificity</th>\n",
    "<th>Precision</th>\n",
    "<th>Recall</th>\n",
    "<th>Accuracy</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>E1</td>\n",
    "<td>M1,M5,M6,M7,M10</td>\n",
    "<td>0.7401</td>\n",
    "<td>0.2977</td>\n",
    "<td>0.5211</td>\n",
    "<td>0.7401</td>\n",
    "<td>0.5224</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>E2</td>\n",
    "<td>M1,M2,M4</td>\n",
    "<td>0.5856</td>\n",
    "<td>0.4603</td>\n",
    "<td>0.5284</td>\n",
    "<td>0.5856</td>\n",
    "<td>0.5240</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>E3</td>\n",
    "<td>M2,M4,M6,M8,M10</td>\n",
    "<td>0.5472</td>\n",
    "<td>0.4705</td>\n",
    "<td>0.51624</td>\n",
    "<td>0.54724</td>\n",
    "<td>0.50949</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>E4</td>\n",
    "<td>M5,M7,M8</td>\n",
    "<td>0.7706</td>\n",
    "<td>0.2723</td>\n",
    "<td>0.5223</td>\n",
    "<td>0.7706</td>\n",
    "<td>0.5254</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>E5</td>\n",
    "<td>M1,M2,M6,M8,M10</td>\n",
    "<td>0.5659</td>\n",
    "<td>0.4502</td>\n",
    "<td>0.5152</td>\n",
    "<td>0.5659</td>\n",
    "<td>0.5090</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:,1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "#fitting the logistic regression model on the training test\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier1 = LogisticRegression(max_iter=10000)\n",
    "classifier1.fit(x_train, y_train)\n",
    "y_pred1 = classifier1.predict(x_test)\n",
    "df['pred1']=y_pred1\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier2 = SGDClassifier()\n",
    "classifier2.fit(x_train, y_train)\n",
    "y_pred2 = classifier2.predict(x_test)\n",
    "df['pred2']=y_pred2\n",
    "\n",
    "#fitting the gaussian process model on the training set\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "classifier3 = GaussianProcessClassifier()\n",
    "classifier3.fit(x_train, y_train)\n",
    "y_pred3 = classifier3.predict(x_test)\n",
    "df['pred3']=y_pred3\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier4=GaussianNB()\n",
    "classifier4.fit(x_train, y_train)\n",
    "y_pred4 = classifier4.predict(x_test)\n",
    "df['pred4']=y_pred4\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "classifier5 = GaussianProcessClassifier()\n",
    "classifier5.fit(x_train, y_train)\n",
    "y_pred5 = classifier5.predict(x_test)\n",
    "df['pred5']=y_pred5\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier6=KNeighborsClassifier(n_neighbors=100)\n",
    "classifier6.fit(x_train, y_train)\n",
    "y_pred6 = classifier6.predict(x_test)\n",
    "df['pred6']=y_pred6\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "classifier7= RadiusNeighborsClassifier(radius=10)\n",
    "classifier7.fit(x_train, y_train)\n",
    "y_pred7 = classifier7.predict(x_test)\n",
    "df['pred7']=y_pred7\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "classifier8 = NearestCentroid()\n",
    "classifier8.fit(x_train, y_train)\n",
    "y_pred8 = classifier8.predict(x_test)\n",
    "df['pred8']=y_pred8\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier9=DecisionTreeClassifier(criterion='entropy')\n",
    "classifier9.fit(x_train, y_train)\n",
    "y_pred9 = classifier9.predict(x_test)\n",
    "df['pred9']=y_pred9\n",
    "\n",
    "#fitting the model on the training test\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier10=RandomForestClassifier(n_estimators=500,criterion='entropy')\n",
    "classifier10.fit(x_train, y_train)\n",
    "y_pred10 = classifier10.predict(x_test)\n",
    "df['pred10']=y_pred10\n",
    "\n",
    "#ensembling\n",
    "df1 = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "df3 = pd.DataFrame()\n",
    "df4 = pd.DataFrame()\n",
    "df5 = pd.DataFrame()\n",
    "\n",
    "df1 = df[['pred1','pred5','pred6','pred7','pred10']].copy()\n",
    "df2 = df[['pred1','pred2','pred4']].copy()\n",
    "df3 = df[['pred2','pred4','pred6','pred8','pred10']].copy()\n",
    "df4 = df[['pred5','pred7','pred8']].copy()\n",
    "df5 = df[['pred1','pred2','pred6','pred8','pred10']].copy()\n",
    "\n",
    "test=df1\n",
    "comp=len(test.columns)\n",
    "y_pred=(test==1).astype(int).sum(axis=1)/comp > 0.5\n",
    "y_pred=y_pred.astype(int)\n",
    "\n",
    "#confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "#sensitiviry\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "\n",
    "#specificity\n",
    "specificity=(tn)/(tn+fp)\n",
    "\n",
    "#precision\n",
    "precision=(tp)/(tp+fp)\n",
    "\n",
    "#recall\n",
    "recall=(tp)/(tp+fn)\n",
    "\n",
    "#accuracy\n",
    "accuracy=(tn+tp)/(tp+fn+fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.3\tStudy 5 feature selection techniques for given classification data set and report Top five features.\n",
    "\n",
    "### Table 2.3: Study of feature selection techniques\n",
    "\n",
    "<table class=\"table table-bordered\">\n",
    "\n",
    "<tr>\n",
    "<th>Feature Selection Technique</th>\n",
    "<th>Top 5 Features</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>T1 - SelectKBest</td>\n",
    "<td>F14,F15,F16,F17,F20</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>T2 - SelectFdr</td>\n",
    "<td>F4,F5,F13,F14,F15</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>T3 - RFE</td>\n",
    "<td>F3,F4,F14,F17,F18</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>T4 - SelectFromModel</td>\n",
    "<td>F1,F3,F4,F9,F11</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td>T5 - SelectFwe</td>\n",
    "<td>F5,F14,F15,F16,F17</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('classificationDataSet.csv')\n",
    "x = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "#feature selector 1\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "fs1=SelectKBest(k=5)\n",
    "x_new1=fs1.fit_transform(x,y)\n",
    "\n",
    "#feature selector 2\n",
    "from sklearn.feature_selection import SelectFdr\n",
    "fs2=SelectFdr()\n",
    "x_new2=fs2.fit_transform(x,y)\n",
    "\n",
    "#feature selector 3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "estimator = LogisticRegression()\n",
    "from sklearn.feature_selection import RFE\n",
    "fs3=RFE(estimator,5)\n",
    "x_new3=fs3.fit_transform(x,y)\n",
    "\n",
    "#feature selector 4\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "fs4=SelectFromModel(estimator)\n",
    "x_new4=fs4.fit_transform(x,y)\n",
    "\n",
    "#feature selector 5\n",
    "from sklearn.feature_selection import SelectFwe\n",
    "fs5=SelectFwe()\n",
    "x_new5=fs5.fit_transform(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
